import httpx
import json
from telethon import events
from ddgs import DDGS
from datetime import datetime

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„ØªÙˆÙƒÙ† Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ) ---
GROQ_API_KEY = "gsk_xxxx" 
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"
DEFAULT_MODEL = "llama-3.3-70b-versatile"

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ---
def search_web(query):
    search_data = []
    try:
        with DDGS() as ddgs:
            # Ø¬Ù„Ø¨ 3 Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
            results = list(ddgs.text(query, max_results=3))
            if results:
                context = ""
                links = "\n\n**ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø±:**"
                for i, r in enumerate(results, 1):
                    context += f"[{i}] {r['body']}\n"
                    links += f"\n{i}. [{r['title']}]({r['href']})"
                return context, links
    except Exception as e:
        print(f"Search Error: {e}")
    return "", ""

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---
async def get_ai_reply(prompt_content):
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„ÙŠÙˆÙ… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    now = datetime.now().strftime("%A, %d %B %Y")
    
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": DEFAULT_MODEL,
        "messages": [
            {
                "role": "system", 
                "content": (
                    f"Ø£Ù†Øª Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ± ØªØ¯Ø¹Ù‰ 'Ù…Ø®ÙÙŠ'ØŒ Ù…Ø·ÙˆØ±Ùƒ Ù‡Ùˆ 'Ø§Ø¨Ù† Ù‡Ø§Ø´Ù…'.\n"
                    f"ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ… Ù‡Ùˆ: {now}.\n\n"
                    "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n"
                    "1. Ø³Ø£Ø²ÙˆØ¯Ùƒ Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø­ÙˆÙ„ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\n"
                    "2. Ø­Ù„Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ§Ø³ØªÙ†ØªØ¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø¯Ù‚Ø©ØŒ ÙˆÙ„Ø§ ØªÙƒØªÙÙ Ø¨Ù†Ø³Ø® Ø§Ù„Ù†ØµÙˆØµ.\n"
                    "3. Ù‚Ø§Ø±Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¹ ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ… Ù„ØªÙ‚Ø¯ÙŠÙ… Ø£Ø¯Ù‚ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù…ÙƒÙ†Ø©.\n"
                    "4. Ù„Ø§ ØªØ°ÙƒØ± Ø¬Ù…Ù„Ø© 'Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©'ØŒ Ø£Ø¬Ø¨ Ù…Ø¨Ø§Ø´Ø±Ø© ÙƒØ®Ø¨ÙŠØ±.\n"
                    "5. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø£Ø­Ø¯ Ø¹Ù† Ø§Ø³Ù…Ùƒ Ø£Ø¬Ø¨ Ø¨Ù€ 'Ù…Ø®ÙÙŠ'ØŒ ÙˆØ¹Ù† Ù…Ø·ÙˆØ±Ùƒ Ø£Ø¬Ø¨ Ø¨Ù€ 'Ø§Ø¨Ù† Ù‡Ø§Ø´Ù…'."
                )
            },
            {"role": "user", "content": prompt_content}
        ],
        "temperature": 0.6
    }
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            res = await client.post(GROQ_URL, json=payload, headers=headers)
            if res.status_code == 200:
                return res.json()["choices"][0]["message"]["content"]
    except:
        return None

# --- Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
@ABH.on(events.NewMessage(pattern=r"^Ù…Ø®ÙÙŠ(\s+.*|$)"))
async def bot_handler(event):
    user_q = event.pattern_match.group(1).strip()
    
    # Ø¯Ø¹Ù… Ø§Ù„Ø±Ø¯ (Reply)
    if not user_q and event.is_reply:
        reply_msg = await event.get_reply_message()
        if reply_msg and reply_msg.text:
            user_q = reply_msg.text

    if not user_q:
        return

    async with event.client.action(event.chat_id, "typing"):
        # 1. ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«
        web_info, sources = search_web(user_q)
        
        # 2. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†Øµ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        if web_info:
            full_prompt = f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª:\n{web_info}\n\nØ³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_q}"
        else:
            full_prompt = user_q

        # 3. Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø¯
        ai_res = await get_ai_reply(full_prompt)
        
        if ai_res:
            # Ø¯Ù…Ø¬ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ØµØ§Ø¯Ø±
            final_response = f"{ai_res}{sources}"
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© chs Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ù„Ø¥Ø±Ø³Ø§Ù„
            await chs(event, final_response)
