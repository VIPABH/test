import os
import tempfile
import speech_recognition as sr
from telethon import events
from pydub import AudioSegment
import pyttsx3
from ABH import ABH  # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙƒÙ„Ø§ÙŠÙ†Øª Ù…Ù† Ù…Ù„Ù ABH.py

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙˆØª =====
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø®ØªÙŠØ§Ø± ØµÙˆØª Ø¹Ø±Ø¨ÙŠ (Ø¥Ù† ÙˆØ¬Ø¯)
for voice in engine.getProperty('voices'):
    if "ar" in voice.id.lower() or "arabic" in voice.name.lower():
        engine.setProperty('voice', voice.id)
        break

# ===== ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ =====
def speech_to_text(path):
    r = sr.Recognizer()
    with sr.AudioFile(path) as source:
        audio = r.record(source)
    try:
        text = r.recognize_sphinx(audio, language="ar")
        return text
    except sr.UnknownValueError:
        return "âŒ Ù„Ù… Ø£ÙÙ‡Ù… Ø§Ù„ØµÙˆØª"
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¹Ø±Ù: {e}"

# ===== ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª =====
def text_to_speech(text, out_path):
    engine.save_to_file(text, out_path)
    engine.runAndWait()
    return out_path

# ===== Ø£Ù…Ø± ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ =====
@ABH.on(events.NewMessage(pattern=r"^/transcribe$"))
async def transcribe_audio(event):
    if not event.is_reply:
        await event.reply("ğŸ™ï¸ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø± Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©.")
        return

    reply = await event.get_reply_message()
    if not reply.media:
        await event.reply("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ³Ø§Ø¦Ø· ØµÙˆØªÙŠØ©.")
        return

    await event.reply("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…...")

    with tempfile.TemporaryDirectory() as tmp:
        ogg_path = os.path.join(tmp, "voice.ogg")
        wav_path = os.path.join(tmp, "voice.wav")

        await ABH.download_media(reply, file=ogg_path)

        sound = AudioSegment.from_file(ogg_path)
        sound = sound.set_frame_rate(16000).set_channels(1)
        sound.export(wav_path, format="wav")

        text = speech_to_text(wav_path)
        await event.reply(f"ğŸ“ Ø§Ù„Ù†Øµ:\n{text}")

# ===== Ø£Ù…Ø± ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª =====
from pydub import AudioSegment

@ABH.on(events.NewMessage(pattern=r"^/say$"))
async def say_text(event):
    if not event.is_reply:
        await event.reply("ğŸ’¬ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø± Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ù†ØµÙŠØ©.")
        return

    reply = await event.get_reply_message()
    if not reply.text:
        await event.reply("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØµÙˆØª.")
        return

    text = reply.text
    await event.reply("ğŸ§ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª...")

    with tempfile.TemporaryDirectory() as tmp:
        wav_path = os.path.join(tmp, "tts.wav")
        mp3_path = os.path.join(tmp, "tts.mp3")

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ø¨ØµÙŠØºØ© WAV
        text_to_speech(text, wav_path)

        # ØªØ­ÙˆÙŠÙ„ WAV Ø¥Ù„Ù‰ MP3 Ù„ÙŠÙ‚Ø¨Ù„Ù‡Ø§ Telegram
        audio = AudioSegment.from_wav(wav_path)
        audio.export(mp3_path, format="mp3")

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Telegram
        await event.reply(file=mp3_path)
